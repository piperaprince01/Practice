{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_R7_Project2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ61trzsR7JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from sklearn import datasets\n",
        "from skimage import exposure\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTzyc9ozSPYP",
        "colab_type": "code",
        "outputId": "1034efbb-43e7-4355-b0e2-5fcc8958f21a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrlvcALbUkvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=\"/content/gdrive/My Drive/SVHN_single_grey1.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVpImuo6Umy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h5f = h5py.File(file, 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEoer-CYOVU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = h5f['X_train'][:]\n",
        "trainy = h5f['y_train'][:]\n",
        "testx = h5f['X_test'][:]\n",
        "testy = h5f['y_test'][:]\n",
        "valx = h5f['X_val'][:]\n",
        "valy = h5f['y_val'][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWjDUqtahJD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "107fa1c9-ccc4-4802-f7ad-2b53aa15871a"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainy.shape)\n",
        "print(testx.shape)\n",
        "print(testy.shape)\n",
        "print(valx.shape)\n",
        "print(valy.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 32, 32)\n",
            "(42000,)\n",
            "(18000, 32, 32)\n",
            "(18000,)\n",
            "(60000, 32, 32)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLlLEvperEJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainx_k = np.reshape(trainX,(trainX.shape[0],-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7yHxH2uweg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "427f9e90-b671-4cde-8043-faf87c5d8925"
      },
      "source": [
        "trainx_k.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TavKwBzVwttX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testx_k = np.reshape(testx,(testx.shape[0],-1))\n",
        "valx_k = np.reshape(valx,(valx.shape[0],-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoFP8-XaxGJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b96a09be-78be-4698-fba2-e257177f2ca6"
      },
      "source": [
        "print(testx_k.shape)\n",
        "print(valx_k.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18000, 1024)\n",
            "(60000, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71iqImNvxNhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MUYjEthxZ_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff2a717d-1671-41aa-b78d-8e92fb524d1b"
      },
      "source": [
        "accuracy = []\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=1)\n",
        "model.fit(trainx_k, trainy)\n",
        "\n",
        "score = model.score(valx_k, valy)\n",
        "print(score * 100)\n",
        "accuracy.append(score)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klhkz2UxzIif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_predict = model.predict(testx_k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU7myd5O5xFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "cb8ce091-dc1e-49d2-9a72-11d28f6b23a7"
      },
      "source": [
        "print(classification_report(testy, df_predict))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.52      0.49      1814\n",
            "           1       0.50      0.57      0.53      1828\n",
            "           2       0.54      0.48      0.51      1803\n",
            "           3       0.37      0.35      0.36      1719\n",
            "           4       0.60      0.57      0.59      1812\n",
            "           5       0.38      0.33      0.36      1768\n",
            "           6       0.38      0.39      0.39      1832\n",
            "           7       0.63      0.59      0.61      1808\n",
            "           8       0.34      0.37      0.36      1812\n",
            "           9       0.39      0.40      0.40      1804\n",
            "\n",
            "    accuracy                           0.46     18000\n",
            "   macro avg       0.46      0.46      0.46     18000\n",
            "weighted avg       0.46      0.46      0.46     18000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Cu_mgq6XH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "45530322-9b1d-42c1-88ec-c46ce6b41169"
      },
      "source": [
        "print(confusion_matrix(testy, df_predict))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 935   43   51   64   71   65  185   40  170  190]\n",
            " [  51 1034  109  122  123   69   68  119   67   66]\n",
            " [  63  135  872  131   82   74   65  168   79  134]\n",
            " [  67  166  127  610   88  229   82   80  149  121]\n",
            " [  85  195   51   71 1039   55  111   35   98   72]\n",
            " [  94  103   71  220   54  588  203   48  205  182]\n",
            " [ 225   74   51   72  102  154  711   33  295  115]\n",
            " [  65  173  146  100   34   38   48 1071   53   80]\n",
            " [ 150   62   59  130   86  153  267   44  675  186]\n",
            " [ 238   87   89  115   60  113  115   65  192  730]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvpQZ7yS8344",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVkfQ_OhBoAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeZImvkqBsU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "0580cc1a-00b4-4b9c-831d-c3c124b4bcd6"
      },
      "source": [
        "for i in range(0,10): \n",
        "    plt.subplot(1,10,(i+1))\n",
        "    plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.title(trainy[i]);\n",
        "print(\"Labels:\",trainy[0:10])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels: [2 6 7 4 4 0 3 0 7 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABLCAYAAABgOHyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfff2EsvOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KovwQdJFB0a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_nn = tf.keras.Sequential()\n",
        "model_nn.add(tf.keras.layers.Flatten(input_shape=(32,32,)))\n",
        "model_nn.add(tf.keras.layers.Dense(1000,activation='relu'))\n",
        "model_nn.add(tf.keras.layers.Dropout(0.5))\n",
        "model_nn.add(tf.keras.layers.Dense(500,activation='relu'))\n",
        "model_nn.add(tf.keras.layers.Dropout(0.5))\n",
        "model_nn.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "model_nn.add(tf.keras.layers.Dropout(0.3))\n",
        "model_nn.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw0prWlXCCKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_nn.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxquRLRlDIb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "39e92805-4721-4e01-a736-b472b80a69d2"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainy.shape)\n",
        "print(testx.shape)\n",
        "print(testy.shape)\n",
        "print(valx.shape)\n",
        "print(valy.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 32, 32)\n",
            "(42000,)\n",
            "(18000, 32, 32)\n",
            "(18000,)\n",
            "(60000, 32, 32)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y26w6ruRCHGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "3a9c7691-1fa8-4c91-dfeb-5197383c16bd"
      },
      "source": [
        "model_nn.fit(trainX, trainy, \n",
        "          validation_data=(valx, valy), \n",
        "          epochs=50,batch_size=trainX.shape[0])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/50\n",
            "42000/42000 [==============================] - 10s 230us/sample - loss: 280.4265 - acc: 0.1017 - val_loss: 1680.7314 - val_acc: 0.0990\n",
            "Epoch 2/50\n",
            "42000/42000 [==============================] - 10s 229us/sample - loss: 2527.9524 - acc: 0.0979 - val_loss: 7304.8297 - val_acc: 0.1000\n",
            "Epoch 3/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-9f0aef59807e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_nn.fit(trainX, trainy, \n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=50,batch_size=trainX.shape[0])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF1_jcwwCRxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "d4258a0e-250b-474a-b38b-2a1260ac5c66"
      },
      "source": [
        "model_nn.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_5 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1000)              1025000   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               50100     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 1,576,610\n",
            "Trainable params: 1,576,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMlQ2blItqPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_nn1 = tf.keras.Sequential()\n",
        "\n",
        "model_nn1.add(tf.keras.layers.Flatten(input_shape=(32,32,)))\n",
        "model_nn1.add(tf.keras.layers.BatchNormalization())\n",
        "model_nn1.add(tf.keras.layers.Dense(1000,activation='relu'))\n",
        "model_nn1.add(tf.keras.layers.BatchNormalization())\n",
        "model_nn1.add(tf.keras.layers.Dropout(0.5))\n",
        "model_nn1.add(tf.keras.layers.Dense(500,activation='relu'))\n",
        "model_nn1.add(tf.keras.layers.BatchNormalization())\n",
        "model_nn1.add(tf.keras.layers.Dropout(0.5))\n",
        "model_nn1.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "model_nn1.add(tf.keras.layers.Dropout(0.30))\n",
        "model_nn1.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DML24reEt3Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_nn1.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer='sgd',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuMGY4Mft6ek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        },
        "outputId": "7257c24b-9fd6-4fd0-ecfa-c94330ea4419"
      },
      "source": [
        "model_nn1.fit(trainX, trainy, \n",
        "          validation_data=(valx, valy), \n",
        "          epochs=100,batch_size=trainX.shape[0])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 14s 328us/sample - loss: 3.8237 - acc: 0.1048 - val_loss: 33.6265 - val_acc: 0.1005\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.7703 - acc: 0.1071 - val_loss: 22.5211 - val_acc: 0.0985\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.7383 - acc: 0.1079 - val_loss: 17.5902 - val_acc: 0.0962\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.6997 - acc: 0.1071 - val_loss: 14.6482 - val_acc: 0.0959\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 3.6500 - acc: 0.1089 - val_loss: 12.6679 - val_acc: 0.0959\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 13s 319us/sample - loss: 3.6038 - acc: 0.1083 - val_loss: 11.1781 - val_acc: 0.0960\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 3.5983 - acc: 0.1070 - val_loss: 10.0010 - val_acc: 0.0965\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.5442 - acc: 0.1122 - val_loss: 9.1121 - val_acc: 0.0970\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.5404 - acc: 0.1105 - val_loss: 8.3709 - val_acc: 0.0973\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 13s 319us/sample - loss: 3.5030 - acc: 0.1121 - val_loss: 7.7350 - val_acc: 0.0976\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 3.4868 - acc: 0.1120 - val_loss: 7.1877 - val_acc: 0.0978\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.4578 - acc: 0.1129 - val_loss: 6.7188 - val_acc: 0.0981\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.4607 - acc: 0.1121 - val_loss: 6.3108 - val_acc: 0.0985\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.4371 - acc: 0.1119 - val_loss: 5.9516 - val_acc: 0.0985\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.3984 - acc: 0.1144 - val_loss: 5.6474 - val_acc: 0.0988\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.3874 - acc: 0.1133 - val_loss: 5.3620 - val_acc: 0.0992\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.3571 - acc: 0.1147 - val_loss: 5.1349 - val_acc: 0.0997\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.3732 - acc: 0.1156 - val_loss: 4.8986 - val_acc: 0.0998\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.3441 - acc: 0.1136 - val_loss: 4.7039 - val_acc: 0.1001\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.3412 - acc: 0.1145 - val_loss: 4.5336 - val_acc: 0.1001\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.3324 - acc: 0.1154 - val_loss: 4.3744 - val_acc: 0.1007\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.3117 - acc: 0.1159 - val_loss: 4.2515 - val_acc: 0.1010\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.3100 - acc: 0.1151 - val_loss: 4.1260 - val_acc: 0.1013\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.2849 - acc: 0.1191 - val_loss: 4.0033 - val_acc: 0.1020\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.2741 - acc: 0.1196 - val_loss: 3.8942 - val_acc: 0.1024\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.2599 - acc: 0.1194 - val_loss: 3.7960 - val_acc: 0.1030\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 3.2513 - acc: 0.1231 - val_loss: 3.6988 - val_acc: 0.1036\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 14s 337us/sample - loss: 3.2404 - acc: 0.1185 - val_loss: 3.6165 - val_acc: 0.1040\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.2455 - acc: 0.1176 - val_loss: 3.5470 - val_acc: 0.1047\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.2119 - acc: 0.1222 - val_loss: 3.4773 - val_acc: 0.1049\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.2172 - acc: 0.1218 - val_loss: 3.3900 - val_acc: 0.1056\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.2066 - acc: 0.1234 - val_loss: 3.3230 - val_acc: 0.1065\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.2085 - acc: 0.1203 - val_loss: 3.2610 - val_acc: 0.1067\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1905 - acc: 0.1230 - val_loss: 3.2120 - val_acc: 0.1074\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 3.1763 - acc: 0.1210 - val_loss: 3.1605 - val_acc: 0.1078\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.1704 - acc: 0.1228 - val_loss: 3.1121 - val_acc: 0.1083\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.1659 - acc: 0.1240 - val_loss: 3.0660 - val_acc: 0.1094\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1531 - acc: 0.1262 - val_loss: 3.0226 - val_acc: 0.1100\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1451 - acc: 0.1229 - val_loss: 2.9782 - val_acc: 0.1105\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.1606 - acc: 0.1228 - val_loss: 2.9391 - val_acc: 0.1110\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.1356 - acc: 0.1287 - val_loss: 2.9023 - val_acc: 0.1118\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1298 - acc: 0.1267 - val_loss: 2.8732 - val_acc: 0.1129\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1284 - acc: 0.1250 - val_loss: 2.8423 - val_acc: 0.1135\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1082 - acc: 0.1274 - val_loss: 2.8139 - val_acc: 0.1142\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1023 - acc: 0.1281 - val_loss: 2.7824 - val_acc: 0.1152\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.1030 - acc: 0.1300 - val_loss: 2.7536 - val_acc: 0.1160\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0984 - acc: 0.1300 - val_loss: 2.7294 - val_acc: 0.1177\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 3.0833 - acc: 0.1296 - val_loss: 2.7014 - val_acc: 0.1187\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.0885 - acc: 0.1297 - val_loss: 2.6760 - val_acc: 0.1198\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0799 - acc: 0.1307 - val_loss: 2.6520 - val_acc: 0.1212\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.0701 - acc: 0.1302 - val_loss: 2.6316 - val_acc: 0.1223\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 3.0662 - acc: 0.1320 - val_loss: 2.6132 - val_acc: 0.1240\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0555 - acc: 0.1314 - val_loss: 2.5935 - val_acc: 0.1259\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0416 - acc: 0.1376 - val_loss: 2.5701 - val_acc: 0.1279\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0488 - acc: 0.1324 - val_loss: 2.5542 - val_acc: 0.1297\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0382 - acc: 0.1350 - val_loss: 2.5376 - val_acc: 0.1311\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 13s 320us/sample - loss: 3.0391 - acc: 0.1317 - val_loss: 2.5203 - val_acc: 0.1332\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 3.0275 - acc: 0.1336 - val_loss: 2.5070 - val_acc: 0.1351\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0196 - acc: 0.1343 - val_loss: 2.4937 - val_acc: 0.1372\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0163 - acc: 0.1357 - val_loss: 2.4778 - val_acc: 0.1388\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.0169 - acc: 0.1373 - val_loss: 2.4674 - val_acc: 0.1405\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.0071 - acc: 0.1363 - val_loss: 2.4556 - val_acc: 0.1422\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 3.0198 - acc: 0.1307 - val_loss: 2.4432 - val_acc: 0.1440\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 2.9956 - acc: 0.1376 - val_loss: 2.4315 - val_acc: 0.1461\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 3.0032 - acc: 0.1350 - val_loss: 2.4193 - val_acc: 0.1480\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.9874 - acc: 0.1372 - val_loss: 2.4087 - val_acc: 0.1503\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9861 - acc: 0.1408 - val_loss: 2.3976 - val_acc: 0.1521\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9743 - acc: 0.1414 - val_loss: 2.3885 - val_acc: 0.1542\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 2.9790 - acc: 0.1404 - val_loss: 2.3792 - val_acc: 0.1565\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 2.9746 - acc: 0.1371 - val_loss: 2.3704 - val_acc: 0.1577\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 2.9695 - acc: 0.1397 - val_loss: 2.3592 - val_acc: 0.1601\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9481 - acc: 0.1402 - val_loss: 2.3496 - val_acc: 0.1623\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9584 - acc: 0.1408 - val_loss: 2.3392 - val_acc: 0.1650\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 13s 314us/sample - loss: 2.9472 - acc: 0.1429 - val_loss: 2.3296 - val_acc: 0.1674\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9426 - acc: 0.1408 - val_loss: 2.3201 - val_acc: 0.1701\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.9416 - acc: 0.1435 - val_loss: 2.3120 - val_acc: 0.1720\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 14s 323us/sample - loss: 2.9367 - acc: 0.1422 - val_loss: 2.3052 - val_acc: 0.1742\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9139 - acc: 0.1454 - val_loss: 2.2977 - val_acc: 0.1761\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9250 - acc: 0.1442 - val_loss: 2.2890 - val_acc: 0.1786\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 2.9221 - acc: 0.1443 - val_loss: 2.2817 - val_acc: 0.1813\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 2.9120 - acc: 0.1472 - val_loss: 2.2739 - val_acc: 0.1845\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.9099 - acc: 0.1470 - val_loss: 2.2681 - val_acc: 0.1872\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.9037 - acc: 0.1460 - val_loss: 2.2621 - val_acc: 0.1892\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.9129 - acc: 0.1459 - val_loss: 2.2581 - val_acc: 0.1914\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 2.8991 - acc: 0.1461 - val_loss: 2.2520 - val_acc: 0.1941\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.8848 - acc: 0.1489 - val_loss: 2.2457 - val_acc: 0.1964\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.8836 - acc: 0.1485 - val_loss: 2.2404 - val_acc: 0.1985\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.8801 - acc: 0.1491 - val_loss: 2.2348 - val_acc: 0.2007\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 2.8766 - acc: 0.1466 - val_loss: 2.2285 - val_acc: 0.2036\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.8673 - acc: 0.1519 - val_loss: 2.2210 - val_acc: 0.2060\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.8759 - acc: 0.1500 - val_loss: 2.2150 - val_acc: 0.2078\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 2.8657 - acc: 0.1514 - val_loss: 2.2106 - val_acc: 0.2101\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.8625 - acc: 0.1534 - val_loss: 2.2052 - val_acc: 0.2126\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.8505 - acc: 0.1531 - val_loss: 2.2005 - val_acc: 0.2148\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 13s 315us/sample - loss: 2.8427 - acc: 0.1544 - val_loss: 2.1955 - val_acc: 0.2175\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.8412 - acc: 0.1535 - val_loss: 2.1891 - val_acc: 0.2210\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.8377 - acc: 0.1540 - val_loss: 2.1847 - val_acc: 0.2236\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 2.8352 - acc: 0.1547 - val_loss: 2.1801 - val_acc: 0.2255\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 2.8415 - acc: 0.1555 - val_loss: 2.1763 - val_acc: 0.2278\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 13s 317us/sample - loss: 2.8420 - acc: 0.1537 - val_loss: 2.1722 - val_acc: 0.2298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5dfde72240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFSu0jU9uBkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "9d8a72f2-8449-45ec-ff72-7f4bb1d46a7d"
      },
      "source": [
        "model_nn1.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_6 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1000)              1025000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               50100     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 1,586,706\n",
            "Trainable params: 1,581,658\n",
            "Non-trainable params: 5,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoT0qJTU0fpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accscore = model_nn1.evaluate(testx, testy, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmpHFmyU0pPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7acf38bf-8b64-444c-9ad6-0db5f5c88a20"
      },
      "source": [
        "print(accscore)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.1795097268422445, 0.22716667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Du-VJ_08Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Convolution2D, MaxPooling2D,Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXFp6Azk1Hdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_cnn = trainX.reshape(trainX.shape[0], 32,32,1).astype('float32')\n",
        "testx_cnn = testx.reshape(testx.shape[0], 32,32,1).astype('float32')\n",
        "valx_cnn = valx.reshape(valx.shape[0], 32,32,1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFX1Ofb_1VaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cfc66e70-0d08-4b87-ed3b-f4970138a245"
      },
      "source": [
        "print(trainX_cnn.shape)\n",
        "print(testx_cnn.shape)\n",
        "print(valx_cnn.shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 32, 32, 1)\n",
            "(18000, 32, 32, 1)\n",
            "(60000, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fslp9Ruf1cOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "244a5f85-92bf-428a-b953-560d96678dbc"
      },
      "source": [
        "model_cnn = Sequential()\n",
        "    \n",
        "\n",
        "model_cnn.add(Convolution2D(32, 3, 3, input_shape=(32,32,1)))\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(Convolution2D(32, 3, 3))\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(100))\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(Dense(10))\n",
        "model_cnn.add(Activation('softmax'))\n",
        "\n",
        "model_cnn.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0614 11:54:29.270070 140043092977536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0614 11:54:29.279793 140043092977536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0614 11:54:29.285877 140043092977536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  import sys\n",
            "W0614 11:54:29.378283 140043092977536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0614 11:54:29.401008 140043092977536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vny7-Jks1sRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "69575b30-2fd7-479d-a8c0-3d783304fa34"
      },
      "source": [
        "model_cnn.fit(trainX_cnn, trainy, epochs=10,validation_data=(valx_cnn, valy), callbacks=callback_list)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0614 11:55:38.358509 140043092977536 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0614 11:55:38.405509 140043092977536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 169s 4ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 168s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 170s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 171s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 170s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 170s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 168s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 167s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 168s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 167s 4ms/step - loss: 14.5078 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5dfdbad780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI8gGMaM1yMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accscore_cnn = model_cnn.evaluate(testx_cnn, testy, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx1qVGCt8x8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e2eb73d-6528-4807-8c60-5af0cc11b4db"
      },
      "source": [
        "print(accscore_cnn)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14.502703887939454, 0.10022222222222223]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUs6lCKT87zr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "d7a0dc2f-4c4c-4cd4-9f39-9cb8a2d0b835"
      },
      "source": [
        "model_cnn.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               2508900   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,519,478\n",
            "Trainable params: 2,519,478\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRl1xwrM9EZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}